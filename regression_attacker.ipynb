{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONTJbMivZeGuLRdjAsvq7y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/microprediction/endersnotebooks/blob/main/regression_attacker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "ljQZy0kzn5rb",
        "outputId": "3356c562-c5ad-419a-bc11-1ab23f9732e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/microprediction/endersgame.git\n",
            "  Cloning https://github.com/microprediction/endersgame.git to /tmp/pip-req-build-ahgc85_7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/microprediction/endersgame.git /tmp/pip-req-build-ahgc85_7\n",
            "  Resolved https://github.com/microprediction/endersgame.git to commit 0ccd0e66c6171baa04bafc36886e836b5e4aceb5\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from endersgame==0.4.3) (1.26.4)\n",
            "Collecting river (from endersgame==0.4.3)\n",
            "  Downloading river-0.21.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from endersgame==0.4.3) (2.32.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from endersgame==0.4.3) (0.14.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->endersgame==0.4.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->endersgame==0.4.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->endersgame==0.4.3) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->endersgame==0.4.3) (2024.8.30)\n",
            "Requirement already satisfied: pandas<3.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from river->endersgame==0.4.3) (2.2.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.12.1 in /usr/local/lib/python3.10/dist-packages (from river->endersgame==0.4.3) (1.13.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->endersgame==0.4.3) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->endersgame==0.4.3) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=2.1->river->endersgame==0.4.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=2.1->river->endersgame==0.4.3) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=2.1->river->endersgame==0.4.3) (2024.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->endersgame==0.4.3) (1.16.0)\n",
            "Downloading river-0.21.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: endersgame\n",
            "  Building wheel for endersgame (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for endersgame: filename=endersgame-0.4.3-py3-none-any.whl size=33269 sha256=ce37339fe51586dac5f9b0cee4fee707e93c164f518ea5a04b01f0fd98e8355e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-52e7ne1x/wheels/39/24/f0/19aeef5765f9b9f629bab092893ebd3c04bde902d978c742bb\n",
            "Successfully built endersgame\n",
            "Installing collected packages: river, endersgame\n",
            "Successfully installed endersgame-0.4.3 river-0.21.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade git+https://github.com/microprediction/endersgame.git\n",
        "# It's probably fine to use the simpler import by the time your read this :)\n",
        "#!pip install --upgrade endersgame"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression Attacker\n",
        "This notebook demonstrates how to create an `Attacker` described in [attacker.md](https://github.com/microprediction/endersgame/blob/main/endersgame/attackers/attacker.md). You may want to glance at this [notebook](https://github.com/microprediction/endersnotebooks/blob/main/mean_reversion_attacker.ipynb) also, if you seek more context or wish to know how these attackers can be used in a new tournament.\n",
        "\n",
        "Here we'll use the river package to update a running regression."
      ],
      "metadata": {
        "id": "LpCh-JZToCzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from endersgame import Attacker, HORIZON, EPSILON\n",
        "from river import linear_model\n",
        "from collections import deque\n",
        "from endersgame import Attacker\n",
        "from endersgame import stream_generator_generator\n",
        "from pprint import pprint\n",
        "from endersgame.accounting.pnlutil import zero_pnl_summary, add_pnl_summaries"
      ],
      "metadata": {
        "id": "7qxqYHfMqvQ4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a Momentum based Attacker\n",
        "We derive from `Attacker` and use `linear_model.LinearRegression` from the river package to maintain a regression estimate of the value `HORIZON` steps ahead. Then, we `buy` if the prediction is considerably higher than `EPSILON` above the current value, and conversely.\n",
        "\n"
      ],
      "metadata": {
        "id": "4INVybLMsraQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyAttacker(Attacker):\n",
        "    \"\"\"\n",
        "    An attacker that uses an online linear regression model to predict future values\n",
        "    and make trading decisions based on the expected profit exceeding EPSILON.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_lags=5, threshold:float=1.0, burn_in=1000, **kwargs):\n",
        "        \"\"\"\n",
        "        Initializes the attacker.\n",
        "\n",
        "        Parameters:\n",
        "        - lag (int): Number of lagged values to use as features.\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_lags = num_lags                      # Number of lagged values to use as features\n",
        "        self.model = linear_model.LinearRegression(   # Online linear regression model\n",
        "            intercept_init=0.0,  # Initialize intercept to 0\n",
        "            intercept_lr=0.0     # Freeze the intercept (no learning)\n",
        "        )\n",
        "        self.input_queue = deque()                    # Queue to store input vectors and time indices\n",
        "        self.current_ndx = 0                          # Observation index\n",
        "        self.threshold = threshold\n",
        "        self.burn_in = burn_in\n",
        "\n",
        "    def tick(self, x):\n",
        "        \"\"\"\n",
        "        Processes the new data point.\n",
        "\n",
        "        - Updates the time index.\n",
        "        - Maintains a queue of input vectors.\n",
        "        - When the future value arrives after HORIZON steps, updates the model.\n",
        "\n",
        "        Parameters:\n",
        "        - x (float): The new data point.\n",
        "        \"\"\"\n",
        "        # The history is maintained by the parent class; no need to call tick_history()\n",
        "\n",
        "        self.current_ndx += 1\n",
        "        X_t = self.get_recent_history(n=self.num_lags)\n",
        "        if len(X_t) >= self.num_lags:\n",
        "            self.input_queue.append({'ndx': self.current_ndx, 'X': X_t})\n",
        "\n",
        "        # Check if we can update the model with data from HORIZON steps ago\n",
        "        while self.input_queue and self.input_queue[0]['ndx'] <= self.current_ndx - HORIZON:\n",
        "            # Retrieve the input vector and its time index\n",
        "            past_data = self.input_queue.popleft()\n",
        "            X_past = past_data['X']\n",
        "\n",
        "            # The target value y is the data point at time 'time_past + HORIZON'\n",
        "            # Since we're at 'current_time', and 'current_time = time_past + HORIZON', we can use 'x' as y\n",
        "            y = x  # Current data point is the target for the input from HORIZON steps ago\n",
        "\n",
        "            # Prepare the feature dictionary in the form demanded by river package\n",
        "            X_past_dict = {f'lag_{i}': value for i, value in enumerate(X_past)}\n",
        "\n",
        "            # Update the model incrementally\n",
        "            self.model.learn_one(X_past_dict, y)\n",
        "\n",
        "    def predict(self, horizon=HORIZON):\n",
        "        \"\"\"\n",
        "        Makes a prediction for HORIZON steps ahead and decides whether to buy, sell, or hold.\n",
        "\n",
        "        Parameters:\n",
        "        - horizon (int): The prediction horizon (should be HORIZON).\n",
        "\n",
        "        Returns:\n",
        "        - int: 1 for buy, -1 for sell, 0 for hold.\n",
        "        \"\"\"\n",
        "        if self.current_ndx < self.burn_in:\n",
        "            return 0   # Not enough data for model to be reliable\n",
        "\n",
        "        # Ensure we have enough history to make a prediction\n",
        "        if len(self.history) >= self.num_lags:\n",
        "            # Create the input vector using the most recent 'lag' values\n",
        "            X_t = list(self.history)[-self.num_lags:]\n",
        "            X_t_dict = {f'lag_{i}': value for i, value in enumerate(X_t)}\n",
        "\n",
        "            # Predict the future value HORIZON steps ahead\n",
        "            y_pred = self.model.predict_one(X_t_dict)\n",
        "\n",
        "            # Get the last known value\n",
        "            last_value = X_t[-1]\n",
        "\n",
        "            # Calculate the expected profit\n",
        "            expected_profit = y_pred - last_value\n",
        "\n",
        "            # Decide based on whether expected profit exceeds a multiple of EPSILON\n",
        "            if expected_profit > self.threshold*EPSILON:\n",
        "                return 1  # Buy\n",
        "            elif expected_profit < -self.threshold*EPSILON:\n",
        "                return -1  # Sell\n",
        "            else:\n",
        "                return 0  # Hold\n",
        "        else:\n",
        "            return 0  # Not enough history to make a prediction\n"
      ],
      "metadata": {
        "id": "Cn_fMDz0ukgK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation\n",
        "\n",
        "### `tick` Method\n",
        "\n",
        "The `tick` method processes a new incoming data point and updates the attacker's state accordingly:\n",
        "\n",
        "- **Increment the Time Index**: The method updates `self.current_ndx` to track the current observation index.\n",
        "- **Maintain Input History**: It retrieves the recent history of `num_lags` values and appends the new input vector (`X_t`) to the `input_queue`, associating it with the current index.\n",
        "- **Update the Model**: The method checks if it has received enough future data (after `HORIZON` steps) to use an earlier input vector as a training example. If so, it pairs the input vector from `HORIZON` steps ago with the current data point `x` (used as the target value `y`) and incrementally updates the online regression model.\n",
        "\n",
        "### `predict` Method\n",
        "\n",
        "The `predict` method makes a decision based on the model’s prediction for the value `HORIZON` steps ahead:\n",
        "\n",
        "- **Burn-in Check**: If the number of processed data points is less than the `burn_in` threshold, the model refrains from making predictions.\n",
        "- **Prepare Input Features**: It checks if there's enough history to form an input vector of `num_lags` values. If there is, it prepares a dictionary of lagged values (`X_t_dict`) to be used by the model.\n",
        "- **Prediction**: The method predicts the next value `HORIZON` steps ahead using the online regression model.\n",
        "- **Decision Logic**: It calculates the expected profit by comparing the predicted future value with the last known value. If the expected profit exceeds a threshold (a multiple of `EPSILON`), it returns:\n",
        "  - `1` (buy) if the profit is positive,\n",
        "  - `-1` (sell) if the profit is negative,\n",
        "  - `0` (hold) if the profit is too small to act upon.\n"
      ],
      "metadata": {
        "id": "tQ68K8PCMAlo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the attacker on mock data\n",
        "We use `tick_and_predict` from the parent class as this will track profit and loss for us."
      ],
      "metadata": {
        "id": "lh6jpef0vAjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attacker = MyAttacker()               # Always reset an attacker\n",
        "\n",
        "xs = [1,3,4,2,4,5,1,5,2,5,10]*100\n",
        "for x in xs:\n",
        "   y = attacker.tick_and_predict(x=x)"
      ],
      "metadata": {
        "id": "S0yzoHAOv9W4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the attacker on real data\n",
        "We reset the attacker every time it encounters a new stream, but track aggregate statistics."
      ],
      "metadata": {
        "id": "dTsfKoLo3lIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_gen = stream_generator_generator(category='train')    # <-- You might want to change 'train' to 'test'\n",
        "attacker = MyAttacker(num_lags=2, threshold=2.0, burn_in=1000)\n",
        "total_pnl = zero_pnl_summary()\n",
        "for stream in gen_gen:\n",
        "    for message in stream:\n",
        "        attacker.tick_and_predict(x=message['x'])\n",
        "    stream_pnl = attacker.pnl.summary()\n",
        "    total_pnl = add_pnl_summaries(total_pnl,stream_pnl)\n",
        "\n",
        "total_pnl.update({'profit_per_decision':total_pnl['total_profit']/total_pnl['num_resolved_decisions']})\n",
        "pprint(total_pnl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqfStlKN3m5s",
        "outputId": "589de881-85cf-4b88-9c99-41aee7cfa265"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'current_ndx': 19871117,\n",
            " 'losses': 10143598,\n",
            " 'num_resolved_decisions': 19788877,\n",
            " 'profit_per_decision': -0.06400384343235338,\n",
            " 'total_profit': -1266564.1852100987,\n",
            " 'wins': 9645279}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And that's all we have. Again, you may want to refer to this [notebook](https://github.com/microprediction/endersnotebooks/blob/main/mean_reversion_attacker.ipynb) also."
      ],
      "metadata": {
        "id": "8vFZx4hCtx2X"
      }
    }
  ]
}